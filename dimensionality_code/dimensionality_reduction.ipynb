{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats, signal\n",
    "from scipy import linalg as LA\n",
    "from numpy.core.records import fromarrays\n",
    "from scipy.io import savemat\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparse_dynamic_wts(st_wts, dyn_wt_dict, send, recv,\n",
    "                           recv_spikes=None, static_only=False):  \n",
    "    dyn_wts = dyn_wt_dict[recv][send]\n",
    "    if st_wts is not None:\n",
    "        if static_only:\n",
    "            return np.tile(st_wts.reshape((1, 1, -1)), (dyn_wts.shape[0], dyn_wts.shape[1], 1))\n",
    "        else:\n",
    "            st_wts = st_wts.reshape((1, 1, -1))\n",
    "            return st_wts + dyn_wts\n",
    "    else:\n",
    "        return dyn_wts\n",
    "    \n",
    "def avg_over_send_spikes(spikes, wts, avg_len=0, plot_wt_count=False):\n",
    "    #spikes is [b, t]\n",
    "    #wts is [b, t, num_delays]\n",
    "    result = np.zeros_like(wts)\n",
    "    counts = np.zeros_like(wts)\n",
    "    for delay in range(wts.shape[2]):\n",
    "        if delay == 0:\n",
    "            result[:, delay:, delay] += spikes*wts[:, :, 0]\n",
    "            counts[:, :, delay] += spikes\n",
    "        else:\n",
    "            result[:, delay:, delay] += spikes[:, :-delay]*wts[:, delay:, delay]\n",
    "            counts[:, delay:, delay] += spikes[:, :-delay]\n",
    "    if avg_len > 0:\n",
    "        final_result = np.copy(result)\n",
    "        final_counts = np.copy(counts)\n",
    "        for i in range(1, avg_len):\n",
    "            final_result[:, i:] += result[:, :-i]\n",
    "            final_counts[:, i:] += counts[:, :-i]\n",
    "        result = final_result\n",
    "        counts = final_counts\n",
    "    if plot_wt_count:\n",
    "        return counts.sum(0)\n",
    "    else:\n",
    "        return result.sum(0) / (counts.sum(0) + 1e-8)\n",
    "    \n",
    "def get_spikes_for_idx(spikes_path, idx, val_only=False, train_only=False):\n",
    "    with h5py.File(spikes_path, 'r') as fin:\n",
    "        if val_only:    \n",
    "            all_spikes = fin['val'][:, :, idx]\n",
    "        elif train_only:\n",
    "            all_spikes = fin['train'][:, :, idx]\n",
    "        else:\n",
    "            spikes_train = fin['train'][:, :, idx]\n",
    "            spikes_val = fin['val'][:, :, idx]\n",
    "            all_spikes = np.concatenate([spikes_train, spikes_val])\n",
    "    return all_spikes\n",
    "\n",
    "def get_wt_img_vals(spikes_path, n1, n2, num_delays, static_wts, dyn_offsets, start_time=0, bin_size=5,\n",
    "                          plot_start=None, plot_end=None, title=None, trial_num=None, dyn_only=False,\n",
    "                             subtract_outsides=False, avg_len=0, plot_max=None, shift_wts=0, use_max=False,\n",
    "                 val_only=False, avg_at_spikes=False, plot_wt_count=False, static_convert=None,\n",
    "                 plot_info=None, normalize_across_time=False, use_wt_zero_max=True,\n",
    "                       use_wt_peak=False, delay_avg_len=None, use_gaussian_delay_averaging=False,\n",
    "                     units=None, id2localidx=None):\n",
    "    if static_convert is not None:\n",
    "        s_n1, s_n2 = static_convert[n1], static_convert[n2]\n",
    "    else:\n",
    "        s_n1, s_n2 = n1, n2\n",
    "    seqstdyn_static_0to1 = static_wts[s_n1, s_n2]\n",
    "    seqstdyn_static_1to0 = static_wts[s_n2, s_n1]\n",
    "    if dyn_only:\n",
    "        forward_dyn_wts = get_sparse_dynamic_wts(None, dyn_offsets, n1, n2)\n",
    "        backward_dyn_wts = get_sparse_dynamic_wts(None, dyn_offsets, n2, n1)\n",
    "    else:\n",
    "        forward_dyn_wts = get_sparse_dynamic_wts(seqstdyn_static_0to1, dyn_offsets, n1, n2)\n",
    "        backward_dyn_wts = get_sparse_dynamic_wts(seqstdyn_static_1to0, dyn_offsets, n2, n1)\n",
    "    if trial_num is not None:\n",
    "        forward_dyn_wts = forward_dyn_wts[trial_num]\n",
    "        backward_dyn_wts = backward_dyn_wts[trial_num]\n",
    "    elif avg_at_spikes:\n",
    "        if id2localidx is not None:\n",
    "            id1, id2 = units.iloc[n1].name, units.iloc[n2].name\n",
    "            sp_n1 = id2localidx[id1]\n",
    "            sp_n2 = id2localidx[id2]\n",
    "        else:\n",
    "            sp_n1, sp_n2 = n1, n2\n",
    "        tmp_sp_1 = get_spikes_for_idx(spikes_path, sp_n1, val_only=True)[:, :forward_dyn_wts.shape[1]]\n",
    "        tmp_sp_2 = get_spikes_for_idx(spikes_path, sp_n2, val_only=True)[:, :forward_dyn_wts.shape[1]]\n",
    "        forward_dyn_wts = avg_over_send_spikes(tmp_sp_1, forward_dyn_wts, avg_len=avg_len, plot_wt_count=plot_wt_count)\n",
    "        backward_dyn_wts = avg_over_send_spikes(tmp_sp_2, backward_dyn_wts, avg_len=avg_len, plot_wt_count=plot_wt_count)\n",
    "    elif use_max:\n",
    "        forward_dyn_wts = forward_dyn_wts.max(0)\n",
    "        backward_dyn_wts = backward_dyn_wts.max(0)\n",
    "    else:\n",
    "        forward_dyn_wts = forward_dyn_wts.mean(0)\n",
    "        backward_dyn_wts = backward_dyn_wts.mean(0)\n",
    "    t = len(forward_dyn_wts)\n",
    "    if plot_end is None:\n",
    "        plot_end = t*bin_size\n",
    "    if plot_start is None:\n",
    "        plot_start = start_time\n",
    "    first_bin = int(plot_start - start_time) // bin_size\n",
    "    last_bin = int(plot_end-start_time) // bin_size\n",
    "    first_time = start_time + first_bin*bin_size\n",
    "    last_time = start_time + last_bin*bin_size\n",
    "    if avg_len > 0 and not avg_at_spikes:\n",
    "        final_forward = np.copy(forward_dyn_wts)\n",
    "        final_backward = np.copy(backward_dyn_wts)\n",
    "        counts = np.ones_like(final_forward)\n",
    "        for i in range(1, avg_len):\n",
    "            final_forward[i:] += forward_dyn_wts[:-i]\n",
    "            final_backward[i:] += backward_dyn_wts[:-i]\n",
    "            counts[i:] += 1\n",
    "        if plot_wt_count:\n",
    "            forward_dyn_wts = counts\n",
    "            backward_dyn_wts = counts\n",
    "        else:\n",
    "            forward_dyn_wts = final_forward / counts\n",
    "            backward_dyn_wts = final_backward / counts\n",
    "    forward_dyn_wts = forward_dyn_wts[first_bin:last_bin]\n",
    "    backward_dyn_wts = backward_dyn_wts[first_bin:last_bin]\n",
    "    forward_dyn_wts = np.copy(forward_dyn_wts)\n",
    "    final_result = np.concatenate([np.flip(forward_dyn_wts.T, (0,)), backward_dyn_wts[:, 1:].T])\n",
    "    \n",
    "    if delay_avg_len is not None:\n",
    "        if use_gaussian_delay_averaging:\n",
    "            final_result = gaussian_filter1d(final_result, delay_avg_len, axis=0, mode='nearest')\n",
    "        else:\n",
    "            tmp_result = np.empty((len(final_result)+2*delay_avg_len, final_result.shape[1]))\n",
    "            tmp_result[:delay_avg_len] = final_result[0]\n",
    "            tmp_result[-delay_avg_len:] = final_result[-1]\n",
    "            tmp_result[delay_avg_len:-delay_avg_len] = final_result\n",
    "            final_tmp_result = np.zeros_like(tmp_result)\n",
    "            for idx in range(delay_avg_len, len(final_tmp_result)-delay_avg_len):\n",
    "                final_tmp_result[idx] = tmp_result[idx-delay_avg_len:idx+delay_avg_len+1].mean(0)\n",
    "            final_result = final_tmp_result[delay_avg_len:-delay_avg_len]\n",
    "    \n",
    "    return final_result, forward_dyn_wts, backward_dyn_wts\n",
    "\n",
    "def compute_sig_for_wts(static_wts, n1, n2, final_result, forward_dyn_wts, backward_dyn_wts, \n",
    "                        normalize_across_time=True,\n",
    "                        use_wt_peak=False, static_convert=None, delay_ind=None,\n",
    "                        plot_std_units=True):   \n",
    "    out_len = forward_dyn_wts.shape[1]//2\n",
    "    outsides = np.concatenate([final_result[:out_len], final_result[-out_len:]])\n",
    "    if normalize_across_time:\n",
    "        means = outsides.mean(keepdims=True)\n",
    "        stds = outsides.std(keepdims=True)+1e-8\n",
    "    else:\n",
    "        means = outsides.mean(0, keepdims=True)\n",
    "        stds = outsides.std(axis=0, keepdims=True)+1e-8\n",
    "    \n",
    "    if delay_ind is not None:\n",
    "        all_wts = np.concatenate([np.flip(forward_dyn_wts.T, (0,)), backward_dyn_wts.T[1:]])\n",
    "        if plot_std_units:\n",
    "            wt_plot_vals = ((all_wts - means)/stds)\n",
    "        else:\n",
    "            wt_plot_vals = all_wts\n",
    "        wt_plot_vals = wt_plot_vals[delay_ind + forward_dyn_wts.shape[1]-1]\n",
    "    elif use_wt_peak:\n",
    "        if plot_std_units:\n",
    "            wt_plot_vals = ((forward_dyn_wts.T - means)/stds)\n",
    "        else:\n",
    "            wt_plot_vals = forward_dyn_wts.T\n",
    "        wt_plot_vals = wt_plot_vals[:-out_len]\n",
    "        if static_convert is not None:\n",
    "            s_n1, s_n2 = static_convert[n1], static_convert[n2]\n",
    "        else:\n",
    "            s_n1, s_n2 = n1, n2\n",
    "        seqstdyn_static_0to1 = static_wts[s_n1, s_n2]\n",
    "        seqstdyn_static_1to0 = static_wts[s_n2, s_n1]\n",
    "        delay_ind = np.abs(seqstdyn_static_0to1[:out_len+1]).argmax()\n",
    "        wt_plot_vals = wt_plot_vals[delay_ind]\n",
    "    \n",
    "    else:\n",
    "        if plot_std_units:\n",
    "            wt_plot_vals = ((forward_dyn_wts.T - means)/stds)\n",
    "        else:\n",
    "            wt_plot_vals = forward_dyn_wts.T\n",
    "        wt_plot_vals = wt_plot_vals[:-out_len]\n",
    "        wt_plot_vals = wt_plot_vals.max(axis=0)\n",
    "    return wt_plot_vals\n",
    "\n",
    "def get_all_spikes(spikes_path):\n",
    "    with h5py.File(spikes_path, 'r') as fin:\n",
    "        spikes_train = fin['train'][:]\n",
    "        spikes_val = fin['val'][:]\n",
    "    all_spikes = np.concatenate([spikes_train, spikes_val])\n",
    "    return all_spikes\n",
    "\n",
    "def get_dim(data, dim_thresh, filter_width):\n",
    "    if filter_width > 0:\n",
    "        out = np.zeros_like(data)\n",
    "        fltHL = int(np.ceil(3*filter_width))\n",
    "        flt = scipy.stats.norm.pdf(np.arange(-fltHL, fltHL+1), 0, filter_width)\n",
    "        yDim, T = data.shape\n",
    "        nm = scipy.signal.convolve(flt, np.ones(T))\n",
    "\n",
    "        for i in range(yDim):\n",
    "            ys = scipy.signal.convolve(flt, data[i]) / nm\n",
    "            out[i] = ys[fltHL:-fltHL]\n",
    "        data = out\n",
    "    data = data.T\n",
    "    \n",
    "    # run PCA\n",
    "    data -= np.mean(data, axis=0)\n",
    "    cov = np.cov(data, rowvar = False)\n",
    "    evals, evecs = LA.eig(cov)\n",
    "    \n",
    "    idx = np.argsort(evals)[::-1]\n",
    "    evecs = evecs[:,idx]\n",
    "    evals = evals[idx]\n",
    "    cum_scores = np.cumsum(evals)/np.sum(evals)\n",
    "    dim = (cum_scores > dim_thresh).nonzero()[0][0]\n",
    "    return dim, cum_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_dir='session_data'\n",
    "out_dir = 'figures/dimensionality_data/'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "use_stronger_pair_filtering = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = [766640955,767871931,768515987,771160300,771990200,774875821,778240327,\n",
    "            778998620,779839471,781842082,786091066,787025148,789848216,793224716,\n",
    "            794812542,816200189,819186360,819701982,821695405,829720705,831882777,\n",
    "            835479236,839068429,839557629,840012044,847657808]\n",
    "\n",
    "plot_start=-100\n",
    "plot_end=400\n",
    "start_time=-150\n",
    "bin_size=5\n",
    "start_bin = (plot_start-start_time)//5\n",
    "end_bin = (plot_end-start_time)//5\n",
    "\n",
    "dim_thresh = 0.95\n",
    "filter_width=0\n",
    "\n",
    "max_ratio = 0\n",
    "max_diff = 0\n",
    "max_ratio_sess = None\n",
    "max_diff_sess = None\n",
    "\n",
    "for session in tqdm(sessions):\n",
    "    data_dir = os.path.join(root_data_dir, str(session))\n",
    "    spikes_5ms_path = os.path.join(root_data_dir, str(session), 'spikes_all_5ms.h5')\n",
    "    spikes_5ms = get_all_spikes(spikes_5ms_path)\n",
    "    spikes_5ms = spikes_5ms.mean(0).T\n",
    "    model_1ms_dir = os.path.join(data_dir, 'model_1ms')\n",
    "    model_5ms_dir = os.path.join(data_dir, 'model_5ms')\n",
    "    \n",
    "    if use_stronger_pair_filtering:\n",
    "        pair_file = os.path.join(data_dir, 'model_5ms_extrafilter', 'pairs.npy')\n",
    "        bin5_dyn_path = os.path.join(data_dir, 'model_5ms_extrafilter', 'dynamic_offsets_val.npy')\n",
    "        allp_static_wts_5ms_path = os.path.join(model_5ms_dir, 'static_weights_val.npy')\n",
    "    else:\n",
    "        pair_file = os.path.join(data_dir, 'model_5ms', 'pairs.npy')\n",
    "        bin5_dyn_path = os.path.join(model_5ms_dir, 'dynamic_offsets_val.npy')\n",
    "        allp_static_wts_5ms_path = os.path.join(model_5ms_dir, 'static_weights_val.npy')\n",
    "        bin5_spikes_path = os.path.join(data_dir, 'spikes_all_5ms.h5')\n",
    "   \n",
    "    \n",
    "    pairs = np.load(pair_file)\n",
    "\n",
    "    used_n = np.unique(pairs)\n",
    "    valid = np.array([n in used_n for n in range(len(spikes_5ms))])\n",
    "    spikes_5ms = spikes_5ms[valid, start_bin:end_bin]\n",
    "    spikes_5ms_full = spikes_5ms[:, start_bin:end_bin]\n",
    "\n",
    "    allp_static_wts = np.load(allp_static_wts_5ms_path)[0]\n",
    "    allp_dyn_wts = np.load(bin5_dyn_path, allow_pickle=True).item()\n",
    "    pairs = np.load(pair_file)\n",
    "\n",
    "    all_pair_sig = []\n",
    "    cum_wt_dim = []\n",
    "    wt_dims = []\n",
    "    sp_dims = []\n",
    "    sp_dims_full = []\n",
    "    \n",
    "    for pair_idx in range(len(pairs)):\n",
    "        n1, n2 = pairs[pair_idx]\n",
    "        avg_len = 0\n",
    "        use_wt_peak = True\n",
    "        avg_at_spikes=True\n",
    "        use_corrected_jpsth=False\n",
    "        allp_wts_im, allp_wt_f, allp_wt_b = get_wt_img_vals(spikes_5ms_path, n1, n2, 10, allp_static_wts, allp_dyn_wts, \n",
    "                                                            start_time=-150, bin_size=5,\n",
    "                                                            plot_start=-100, plot_end=400,\n",
    "                                                            avg_len=avg_len,\n",
    "                                                            avg_at_spikes=avg_at_spikes, static_convert=None,\n",
    "                                                            normalize_across_time=True, use_wt_peak=use_wt_peak)\n",
    "        allp_wts_sig = compute_sig_for_wts(allp_static_wts, n1, n2, allp_wts_im, allp_wt_f, allp_wt_b,\n",
    "                                           static_convert=None,\n",
    "                                           normalize_across_time=True, use_wt_peak=use_wt_peak)\n",
    "        all_pair_sig.append(allp_wts_sig)\n",
    "    all_pair_sig = np.stack(all_pair_sig)\n",
    "    \n",
    "    tmp_all_pair_sig = all_pair_sig - all_pair_sig.min()\n",
    "\n",
    "    \n",
    "    wt_dim, wt_cum_var = get_dim(tmp_all_pair_sig, dim_thresh, filter_width)\n",
    "    sp_dim, sp_cum_var = get_dim(spikes_5ms, dim_thresh, filter_width)\n",
    "    sp_dim_full, sp_cum_var_full = get_dim(spikes_5ms_full, dim_thresh, filter_width)\n",
    "    \n",
    "    wt_dims.append(wt_dim)\n",
    "    sp_dims.append(sp_dim)\n",
    "    sp_dims_full.append(sp_dim_full)\n",
    "    \n",
    "    cum_wt_dim.append([session, wt_dim, sp_dim, sp_dim_full, len(spikes_5ms), len(pairs), len(spikes_5ms_full)])\n",
    "    print(cum_wt_dim)\n",
    "    \n",
    "    dim_ratio = wt_dim/sp_dim\n",
    "    if dim_ratio > max_ratio:\n",
    "        max_ratio = dim_ratio\n",
    "        max_ratio_sess = session\n",
    "        max_ratio_vals = [wt_dim, sp_dim]\n",
    "    dim_diff = wt_dim - sp_dim\n",
    "    if dim_diff > max_diff:\n",
    "        max_diff = dim_diff\n",
    "        max_diff_sess = session\n",
    "        max_diff_vals = [wt_dim, sp_dim]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0 831882777 [32, 4]\n",
      "29 786091066 [36, 7]\n"
     ]
    }
   ],
   "source": [
    "print(max_ratio, max_ratio_sess, max_ratio_vals)\n",
    "print(max_diff, max_diff_sess, max_diff_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = 831882777\n",
    "plot_smoothing_kernel_width = 0\n",
    "\n",
    "data_dir = os.path.join(root_data_dir, str(session))\n",
    "spikes_5ms_path = os.path.join(root_data_dir, str(session), 'spikes_all_5ms.h5')\n",
    "spikes_5ms = get_all_spikes(spikes_5ms_path)\n",
    "spikes_5ms = spikes_5ms.mean(0).T\n",
    "model_1ms_dir = os.path.join(data_dir, 'model_1ms')\n",
    "model_5ms_dir = os.path.join(data_dir, 'model_5ms')\n",
    "\n",
    "if use_stronger_pair_filtering:\n",
    "    pair_file = os.path.join(data_dir, 'model_5ms_extrafilter', 'pairs.npy')\n",
    "    bin5_dyn_path = os.path.join(data_dir, 'model_5ms_extrafilter', 'dynamic_offsets_val.npy')\n",
    "    allp_static_wts_5ms_path = os.path.join(model_5ms_dir, 'static_weights_val.npy')\n",
    "else:\n",
    "    pair_file = os.path.join(data_dir, 'model_5ms', 'pairs.npy')\n",
    "    bin5_dyn_path = os.path.join(model_5ms_dir, 'dynamic_offsets_val.npy')\n",
    "    allp_static_wts_5ms_path = os.path.join(model_5ms_dir, 'static_weights_val.npy')\n",
    "    bin5_spikes_path = os.path.join(data_dir, 'spikes_all_5ms.h5')\n",
    "\n",
    "\n",
    "pairs = np.load(pair_file)\n",
    "\n",
    "used_n = np.unique(pairs)\n",
    "valid = np.array([n in used_n for n in range(len(spikes_5ms))])\n",
    "spikes_5ms_full = spikes_5ms[:, start_bin:end_bin]\n",
    "spikes_5ms = spikes_5ms[valid, start_bin:end_bin]\n",
    "\n",
    "allp_static_wts = np.load(allp_static_wts_5ms_path)[0]\n",
    "allp_dyn_wts = np.load(bin5_dyn_path, allow_pickle=True).item()\n",
    "\n",
    "all_pair_sig = []\n",
    "for pair_idx in range(len(pairs)):\n",
    "    n1, n2 = pairs[pair_idx]\n",
    "    avg_len = 0\n",
    "    use_wt_peak = True\n",
    "    avg_at_spikes=True\n",
    "    use_corrected_jpsth=False\n",
    "    allp_wts_im, allp_wt_f, allp_wt_b = get_wt_img_vals(spikes_5ms_path, n1, n2, 10, allp_static_wts, allp_dyn_wts, \n",
    "                                                        start_time=-150, bin_size=5,\n",
    "                                                        plot_start=-100, plot_end=400,\n",
    "                                                        avg_len=avg_len,\n",
    "                                                        avg_at_spikes=avg_at_spikes, static_convert=None,\n",
    "                                                        normalize_across_time=True, use_wt_peak=use_wt_peak)\n",
    "    allp_wts_sig = compute_sig_for_wts(allp_static_wts, n1, n2, allp_wts_im, allp_wt_f, allp_wt_b,\n",
    "                                       static_convert=None,\n",
    "                                       normalize_across_time=True, use_wt_peak=use_wt_peak)\n",
    "    all_pair_sig.append(allp_wts_sig)\n",
    "all_pair_sig = np.stack(all_pair_sig)\n",
    "\n",
    "tmp_all_pair_sig = all_pair_sig - all_pair_sig.min()\n",
    "\n",
    "wt_dims = []\n",
    "sp_dims = []\n",
    "sp_dims_full = []\n",
    "filter_widths = np.arange(11)\n",
    "\n",
    "for filter_width in filter_widths:\n",
    "    wt_dim, wt_cum_var = get_dim(tmp_all_pair_sig, dim_thresh, filter_width)\n",
    "    sp_dim, sp_cum_var = get_dim(spikes_5ms, dim_thresh, filter_width)\n",
    "    sp_dim_full, sp_cum_var_full = get_dim(spikes_5ms_full, dim_thresh, filter_width)\n",
    "    \n",
    "   \n",
    "    wt_dims.append(wt_dim)\n",
    "    sp_dims.append(sp_dim)\n",
    "    sp_dims_full.append(sp_dim_full)\n",
    "    \n",
    "    if filter_width == plot_smoothing_kernel_width:\n",
    "        plot_cum_vars = [wt_cum_var, sp_cum_var, sp_cum_var_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(filter_widths, wt_dims, label='Model')\n",
    "ax.plot(filter_widths, sp_dims, label='Spikes (Model pairs only)')\n",
    "ax.plot(filter_widths, sp_dims_full, label='Spikes (full)')\n",
    "ax.set_xlabel('Smoothing Kernel Width')\n",
    "ax.set_ylabel('Dimensionality')\n",
    "ax.legend()\n",
    "fig.show()\n",
    "\n",
    "plot_lines = np.stack([\n",
    "    filter_widths,\n",
    "    wt_dims,\n",
    "    sp_dims,\n",
    "    sp_dims_full,\n",
    "],axis=1)\n",
    "out_path = os.path.join(out_dir, '%d_dimensionality.csv')\n",
    "np.savetxt(out_path, plot_lines, delimiter=',', header='kernel_width,model,spikes_model_pairs,spikes_full')\n",
    "print(max(wt_dims), max(sp_dims), max(sp_dims_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(1, len(plot_cum_vars[0])+1), plot_cum_vars[0], label='Model')\n",
    "ax.plot(np.arange(1, len(plot_cum_vars[1])+1), plot_cum_vars[1], label='Spikes (Model pairs only)')\n",
    "ax.plot(np.arange(1, len(plot_cum_vars[2])+1), plot_cum_vars[2], label='Spikes (full)')\n",
    "ax.set_xlabel('Latent Dimensionality')\n",
    "ax.set_ylabel('Cumulative % variance explained')\n",
    "ax.legend()\n",
    "fig.show()\n",
    "\n",
    "out_path = os.path.join(out_dir, '%d_variance_model.csv')\n",
    "plot_lines = np.stack([\n",
    "    np.arange(1, len(plot_cum_vars[0])+1),\n",
    "    plot_cum_vars[0],\n",
    "], axis=1)\n",
    "np.savetxt(out_path, plot_lines, delimiter=',', header='latent_dimensionality,cum_var_explained')\n",
    "\n",
    "out_path = os.path.join(out_dir, '%d_variance_spikes_pairs.csv')\n",
    "plot_lines = np.stack([\n",
    "    np.arange(1, len(plot_cum_vars[1])+1),\n",
    "    plot_cum_vars[1],\n",
    "], axis=1)\n",
    "np.savetxt(out_path, plot_lines, delimiter=',', header='latent_dimensionality,cum_var_explained')\n",
    "\n",
    "out_path = os.path.join(out_dir, '%d_variance_spikes_full.csv')\n",
    "plot_lines = np.stack([\n",
    "    np.arange(1, len(plot_cum_vars[2])+1),\n",
    "    plot_cum_vars[2],\n",
    "], axis=1)\n",
    "np.savetxt(out_path, plot_lines, delimiter=',', header='latent_dimensionality,cum_var_explained')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AllenSDK_v2",
   "language": "python",
   "name": "allensdk_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
